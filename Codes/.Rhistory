a
b
#or b <- levels(prob.test)[prob.test]
c <- attributes(prob.test)$prob #proportion of the votes for the winning class
c
d <- prob.test == Tags
result <- data.frame(Doc=a, Predict=b,Prob=c,Correct= d)
result
#vinstall.packages("arules")
library("arules")
#create a sparse matrix
grocery <- read.transactions(".\\grocery.csv",  sep = ",")
summary(grocery)
#plot frequent items with min support = 0.1
itemFrequencyPlot(Groceries, support = 0.15)
#use apriori to generate rules
rules <- apriori(Groceries,
parameter = list(support = 0.006, confidence = 0.25, minlen = 2))
#get top five highest lift rules
inspect(sort(rules, by="lift")[1:5])
#find subset of the rules with berrries appearing in the rule
sub.rules <- subset(rules, rhs %in% "tropical fruit")
inspect(sub.rules)
sub.rules.2 <- subset(rules, items %in% c("berries", "yogurt") & lift > 3)
# or
sub.rules.2 <- subset(rules, items %in% c("berries", "yogurt") & lift > 3)
inspect(sub.rules.2)
sub.rules.2 <- subset(rules, (items %in% "berries" | items %in% "yogurt") & lift > 3)
# or
sub.rules.2 <- subset(rules, items %in% c("berries", "yogurt") & lift > 3)
inspect(sub.rules.2)
sub.rules.2
#vinstall.packages("arules")
library("arules")
#create a sparse matrix
grocery <- read.transactions(".\\grocery.csv",  sep = ",")
summary(grocery)
#plot frequent items with min support = 0.1
itemFrequencyPlot(Groceries, support = 0.15)
#use apriori to generate rules
rules <- apriori(Groceries,
parameter = list(support = 0.006, confidence = 0.25, minlen = 2))
#get top five highest lift rules
inspect(sort(rules, by="lift")[1:5])
#find subset of the rules with berrries appearing in the rule
sub.rules <- subset(rules, rhs %in% "tropical fruit")
inspect(sub.rules)
sub.rules.2 <- subset(rules, (items %in% "berries" | items %in% "yogurt") & lift > 3)
# or
sub.rules.2 <- subset(rules, items %in% c("berries", "yogurt") & lift > 3)
sub.rules.2
inspect(sub.rules.2)
iris
dim(iris)
library(ggplot2)
ggplot(iris, aes(Petal.Length, Petal.Width, color = Species)) + geom_point()
ggplot(iris, aes(Sepal.Length, Sepal.Width, color = Species)) + geom_point()
ggplot(iris, aes(Petal.Length, Petal.Width, color = Species)) + geom_point()
ggplot(iris, aes(Sepal.Length, Sepal.Width, color = Species)) + geom_point()
head(iris)
#this command initializes R's random number generator to a specific sequence
#so set.seed to ensure reproducibility.
?set.seed
set.seed(20)
iris[, 3:4]
irisCluster <- kmeans(iris[, 3:4], 3)
irisCluster
#how good the clustering result?
table(irisCluster$cluster, iris$Species)
#plot the data to see the clusters
irisCluster$cluster.1 <- as.factor(irisCluster$cluster)
irisCluster$cluster.1
ggplot(iris, aes(Petal.Length, Petal.Width, color = irisCluster$cluster.1)) + geom_point()
#about between_SS and total_SS
irisCluster$centers
irisCluster$cluster
irisCluster$totss
irisCluster$withinss
mean1 <- mean(iris$Petal.Length)
mean2 <- mean(iris$Petal.Width)
#compute total_SS by hand
sum((iris$Petal.Length - mean1)^2 + (iris$Petal.Width - mean2)^2)
#compute within-cluster sum of squares for cluster 1
mean1 <- irisCluster$centers[1,1]
library(tm)#Framework for textmining.
library(SnowballC)#Provides wordStem() for stemming.
Doc1.Train.Source <- DirSource(paste(getwd(),"/DemoData/News2/20news-bydate-train/sci.space",sep=""))
Doc1.Train <- Corpus(URISource(Doc1.Train.Source$filelist[1:100]), readerControl=list(reader=readPlain))
Doc1.Test.Source <- DirSource(paste(getwd(),"/DemoData/News2/20news-bydate-test/sci.space",sep=""))
Doc1.Test <- Corpus(URISource(Doc1.Train.Source$filelist[1:100]), readerControl=list(reader=readPlain))
Doc2.Train.Source <- DirSource(paste(getwd(),"/DemoData/News2/20news-bydate-train/rec.autos",sep=""))
Doc2.Train <- Corpus(URISource(Doc1.Train.Source$filelist[1:100]), readerControl=list(reader=readPlain))
Doc2.Test.Source <- DirSource(paste(getwd(),"/DemoData/News2/20news-bydate-test/rec.autos",sep=""))
Doc2.Test <- Corpus(URISource(Doc1.Train.Source$filelist[1:100]), readerControl=list(reader=readPlain))
# merge 4 corpus
merge.corpus <- c(Doc1.Train,Doc1.Test,Doc2.Train,Doc2.Test)
merge.corpus
#Preprocessing
# Convert to lower case
merge.corpus.tranf <- tm_map(merge.corpus, content_transformer(tolower))
# Remove Punctuation
merge.corpus.tranf <- tm_map(merge.corpus.tranf, removePunctuation)
# Remove stop words
merge.corpus.tranf <- tm_map(merge.corpus.tranf, removeWords, stopwords("english"))
# specify your stopwords as a character vector
merge.corpus.tranf <- tm_map(merge.corpus.tranf, removeWords, c("since", "let", "yes", "every", "yeah"))
# ignore extremely rare words i.e. terms that appear in less then 1% of the documents
minTermFreq <- 5
dtm = DocumentTermMatrix(merge.corpus,
control = list(
minWordLength = 2, minDocFreq = 5
#wordLengths=c(2, Inf),
#bounds = list(global = c(minTermFreq, Inf))
))
dtm.matrix = as.matrix(dtm)
dtm.matrix[200:230, 20:30]
train.doc <- dtm.matrix[c(1:100,201:300),]
test.doc <- dtm.matrix[c(101:200,301:400),]
Tags <- factor(c(rep("Sci",100), rep("Rec",100)))
dim(train.doc)
dim(test.doc)
length(Tags)
library(class) # Using kNN
prob.test<- knn(train.doc, test.doc, Tags, k = 3, prob=TRUE)
prob.test
# Display Classification Results
a <- c(1:length(prob.test)) #document ids
b <- prob.test #predicts by the algorithm
#or b <- levels(prob.test)[prob.test]
c <- attributes(prob.test)$prob #proportion of the votes for the winning class
d <- prob.test == Tags
result <- data.frame(Doc=a, Predict=b,Prob=c,Correct= d)
result
#create a sparse matrix
grocery <- read.transactions(".\\grocery.csv",  sep = ",")
summary(grocery)
#plot frequent items with min support = 0.1
itemFrequencyPlot(Groceries, support = 0.15)
#use apriori to generate rules
rules <- apriori(Groceries,
parameter = list(support = 0.006, confidence = 0.25, minlen = 2))
#get top five highest lift rules
inspect(sort(rules, by="lift")[1:5])
#find subset of the rules with berrries appearing in the rule
sub.rules <- subset(rules, rhs %in% "tropical fruit")
inspect(sub.rules)
sub.rules.2 <- subset(rules, (items %in% "berries" | items %in% "yogurt") & lift > 3)
# or
sub.rules.2 <- subset(rules, items %in% c("berries", "yogurt") & lift > 3)
sub.rules.2
inspect(sub.rules.2)
iris
dim(iris)
library(ggplot2)
ggplot(iris, aes(Petal.Length, Petal.Width, color = Species)) + geom_point()
ggplot(iris, aes(Sepal.Length, Sepal.Width, color = Species)) + geom_point()
head(iris)
#this command initializes R's random number generator to a specific sequence
#so set.seed to ensure reproducibility.
?set.seed
set.seed(20)
iris[, 3:4]
irisCluster <- kmeans(iris[, 3:4], 3)
?kmeans
irisCluster
#how good the clustering result?
table(irisCluster$cluster, iris$Species)
#plot the data to see the clusters
irisCluster$cluster.1 <- as.factor(irisCluster$cluster)
irisCluster$cluster.1
ggplot(iris, aes(Petal.Length, Petal.Width, color = irisCluster$cluster.1)) + geom_point()
#about between_SS and total_SS
irisCluster$centers
install.packages("randomForest")
library(randomForest)
# Load the dataset and explore
data1 &lt;- read.csv(file.choose(), header = TRUE)
# Load the dataset and explore
data1 <- read.csv(file.choose(), header = TRUE)
head(data1)
str(data1)
summary(data1)
# Split into Train and Validation sets
# Training Set : Validation Set = 70 : 30 (random)
set.seed(100)
nrow(data1)
train <- sample(nrow(data1), 0.7*nrow(data1), replace = FALSE)
TrainSet <- data1[train,]
ValidSet <- data1[-train,]
TrainSet
ValidSet
summary(TrainSet)
summary(ValidSet)
# Create a Random Forest model with default parameters
model1 <- randomForest(Condition ~ ., data = TrainSet, importance = TRUE)
model1
# install.packages("randomForest")
library(randomForest)
# Load the dataset and explore
data1 <- read.csv(file.choose(), header = TRUE)
head(data1)
str(data1)
summary(data1)
# Split into Train and Validation sets
# Training Set : Validation Set = 70 : 30 (random)
set.seed(100)
train <- sample(nrow(data1), 0.7*nrow(data1), replace = FALSE)
TrainSet <- data1[train,]
ValidSet <- data1[-train,]
summary(TrainSet)
summary(ValidSet)
# Create a Random Forest model with default parameters
model1 <- randomForest(Condition ~ ., data = TrainSet, importance = TRUE)
model1
# Create a Random Forest model with default parameters
model1 <- randomForest(condition ~ ., data = TrainSet, importance = TRUE)
model1
# Fine tuning parameters of Random Forest model
model2 <- randomForest(condition ~ ., data = TrainSet, ntree = 500, mtry = 6, importance = TRUE)
model2
# Predicting on train set
predTrain <- predict(model2, TrainSet, type = "class")
# Checking classification accuracy
table(predTrain, TrainSet$Condition)
# Checking classification accuracy
table(predTrain, TrainSet$condition)
# Predicting on Validation set
predValid <- predict(model2, ValidSet, type = "class")
# Checking classification accuracy
mean(predValid == ValidSet$Condition)
# Checking classification accuracy
mean(predValid == ValidSet$condition)
table(predValid,ValidSet$condition)
# To check important variables
importance(model2)
varImpPlot(model2)
# To check important variables
importance(model2)
varImpPlot(model2)
varImpPlot(model2)
# Using For loop to identify the right mtry for model
a=c()
i=5
for (i in 3:8) {
model3 <- randomForest(Condition ~ ., data = TrainSet, ntree = 500, mtry = i, importance = TRUE)
predValid <- predict(model3, ValidSet, type = "class")
a[i-2] = mean(predValid == ValidSet$Condition)
}
i=5
for (i in 3:8) {
model3 <- randomForest(condition ~ ., data = TrainSet, ntree = 500, mtry = i, importance = TRUE)
predValid <- predict(model3, ValidSet, type = "class")
a[i-2] = mean(predValid == ValidSet$condition)
}
a
a
plot(3:8,a)
install.packages("rpart")
install.packages("caret")
install.packages("e1071")
library(rpart)
library(caret)
library(e1071)
model_dt = train(Condition ~ ., data = TrainSet, method = "rpart")
model_dt = train(condition ~ ., data = TrainSet, method = "rpart")
model_dt_1 = predict(model_dt, data = TrainSet)
table(model_dt_1, TrainSet$condition)
mean(model_dt_1 == TrainSet$condition)
# Running on Validation Set
model_dt_vs = predict(model_dt, newdata = ValidSet)
table(model_dt_vs, ValidSet$condition)
mean(model_dt_vs == ValidSet$condition)
model_dt_vs == ValidSet$condition
# install.packages("randomForest")
library(randomForest)
# Load the dataset and explore
data1 <- read.csv(file.choose(), header = TRUE)
head(data1)
str(data1)
summary(data1)
# Split into Train and Validation sets
# Training Set : Validation Set = 70 : 30 (random)
set.seed(100)
train <- sample(nrow(data1), 0.7*nrow(data1), replace = FALSE)
TrainSet <- data1[train,]
ValidSet <- data1[-train,]
summary(TrainSet)
summary(ValidSet)
# Create a Random Forest model with default parameters
model1 <- randomForest(condition ~ ., data = TrainSet, importance = TRUE)
model1
# Fine tuning parameters of Random Forest model
model2 <- randomForest(condition ~ ., data = TrainSet, ntree = 500, mtry = 6, importance = TRUE)
model2
# Create a Random Forest model with default parameters
model1 <- randomForest(condition ~ ., data = TrainSet, mtry = 6, importance = TRUE)
model1
# Create a Random Forest model with default parameters
model1 <- randomForest(condition ~ ., data = TrainSet, mtry = 2, importance = TRUE)
model1
# Fine tuning parameters of Random Forest model
model2 <- randomForest(condition ~ ., data = TrainSet, ntree = 500, mtry = 6, importance = TRUE)
model2
# Predicting on train set
predTrain <- predict(model2, TrainSet, type = "class")
# Checking classification accuracy
table(predTrain, TrainSet$condition)
# Predicting on Validation set
predValid <- predict(model2, ValidSet, type = "class")
# Checking classification accuracy
mean(predValid == ValidSet$condition)
table(predValid,ValidSet$condition)
# To check important variables
importance(model2)
varImpPlot(model2)
# Using For loop to identify the right mtry for model
a=c()
i=5
for (i in 3:8) {
model3 <- randomForest(condition ~ ., data = TrainSet, ntree = 500, mtry = i, importance = TRUE)
predValid <- predict(model3, ValidSet, type = "class")
a[i-2] = mean(predValid == ValidSet$condition)
}
a
predValid == ValidSet$condition
a
plot(3:8,a)
summary(data1)
# Using For loop to identify the right mtry for model
a=c()
i=5
for (i in 3:10) {
model3 <- randomForest(condition ~ ., data = TrainSet, ntree = 500, mtry = i, importance = TRUE)
predValid <- predict(model3, ValidSet, type = "class")
a[i-2] = mean(predValid == ValidSet$condition)
}
a
summary(data1)
# Using For loop to identify the right mtry for model
a=c()
i=5
for (i in 2:8) {
model3 <- randomForest(condition ~ ., data = TrainSet, ntree = 500, mtry = i, importance = TRUE)
predValid <- predict(model3, ValidSet, type = "class")
a[i-2] = mean(predValid == ValidSet$condition)
}
a
# Using For loop to identify the right mtry for model
a=c()
i=5
for (i in 2:8) {
model3 <- randomForest(condition ~ ., data = TrainSet, ntree = 500, mtry = i, importance = TRUE)
predValid <- predict(model3, ValidSet, type = "class")
a[i-1] = mean(predValid == ValidSet$condition)
}
a
str(data1)
summary(data1)
# Load the dataset and explore
data1 <- read.csv(file.choose(), header = TRUE)
head(data1)
str(data1)
summary(data1)
# Split into Train and Validation sets
# Training Set : Validation Set = 70 : 30 (random)
set.seed(100)
train <- sample(nrow(data1), 0.7*nrow(data1), replace = FALSE)
TrainSet <- data1[train,]
ValidSet <- data1[-train,]
summary(TrainSet)
summary(ValidSet)
# Create a Random Forest model with default parameters
model1 <- randomForest(condition ~ ., data = TrainSet, mtry = 2, importance = TRUE)
model1
# Fine tuning parameters of Random Forest model
model2 <- randomForest(condition ~ ., data = TrainSet, ntree = 500, mtry = 6, importance = TRUE)
model2
# Fine tuning parameters of Random Forest model
model2 <- randomForest(condition ~ ., data = TrainSet, ntree = 500, mtry = 9, importance = TRUE)
model2
# Fine tuning parameters of Random Forest model
model2 <- randomForest(condition ~ ., data = TrainSet, ntree = 500, mtry = 8, importance = TRUE)
model2
# Fine tuning parameters of Random Forest model
model2 <- randomForest(condition ~ ., data = TrainSet, ntree = 500, mtry = 6, importance = TRUE)
model2
# Predicting on train set
predTrain <- predict(model2, TrainSet, type = "class")
# Checking classification accuracy
table(predTrain, TrainSet$condition)
# Predicting on Validation set
predValid <- predict(model2, ValidSet, type = "class")
# Checking classification accuracy
mean(predValid == ValidSet$condition)
table(predValid,ValidSet$condition)
# To check important variables
importance(model2)
varImpPlot(model2)
# Using For loop to identify the right mtry for model
a=c()
i=5
for (i in 3:9) {
model3 <- randomForest(condition ~ ., data = TrainSet, ntree = 500, mtry = i, importance = TRUE)
predValid <- predict(model3, ValidSet, type = "class")
a[i-2] = mean(predValid == ValidSet$condition)
}
a
for (i in 3:8) {
model3 <- randomForest(condition ~ ., data = TrainSet, ntree = 500, mtry = i, importance = TRUE)
predValid <- predict(model3, ValidSet, type = "class")
a[i-2] = mean(predValid == ValidSet$condition)
}
a
# Load the dataset and explore
data1 <- read.csv(file.choose(), header = TRUE)
head(data1)
str(data1)
summary(data1)
# Split into Train and Validation sets
# Training Set : Validation Set = 70 : 30 (random)
set.seed(100)
train <- sample(nrow(data1), 0.7*nrow(data1), replace = FALSE)
TrainSet <- data1[train,]
ValidSet <- data1[-train,]
summary(TrainSet)
summary(ValidSet)
# Create a Random Forest model with default parameters
model1 <- randomForest(condition ~ ., data = TrainSet, mtry = 2, importance = TRUE)
model1
# Fine tuning parameters of Random Forest model
model2 <- randomForest(condition ~ ., data = TrainSet, ntree = 500, mtry = 6, importance = TRUE)
model2
# Predicting on train set
predTrain <- predict(model2, TrainSet, type = "class")
# Checking classification accuracy
table(predTrain, TrainSet$condition)
# Predicting on Validation set
predValid <- predict(model2, ValidSet, type = "class")
# Checking classification accuracy
mean(predValid == ValidSet$condition)
table(predValid,ValidSet$condition)
# To check important variables
importance(model2)
varImpPlot(model2)
# Using For loop to identify the right mtry for model
a=c()
i=5
for (i in 3:8) {
model3 <- randomForest(condition ~ ., data = TrainSet, ntree = 500, mtry = i, importance = TRUE)
predValid <- predict(model3, ValidSet, type = "class")
a[i-2] = mean(predValid == ValidSet$condition)
}
a
plot(3:8,a)
# Using For loop to identify the right mtry for model
a=c()
i=5
for (i in 3:6) {
model3 <- randomForest(condition ~ ., data = TrainSet, ntree = 500, mtry = i, importance = TRUE)
predValid <- predict(model3, ValidSet, type = "class")
a[i-2] = mean(predValid == ValidSet$condition)
}
a
# Using For loop to identify the right mtry for model
a=c()
i=5
for (i in 3:7) {
model3 <- randomForest(condition ~ ., data = TrainSet, ntree = 500, mtry = i, importance = TRUE)
predValid <- predict(model3, ValidSet, type = "class")
a[i-2] = mean(predValid == ValidSet$condition)
}
a
# Load the dataset and explore
data1 <- read.csv(file.choose(), header = TRUE)
head(data1)
str(data1)
summary(data1)
# Split into Train and Validation sets
# Training Set : Validation Set = 70 : 30 (random)
set.seed(100)
train <- sample(nrow(data1), 0.7*nrow(data1), replace = FALSE)
TrainSet <- data1[train,]
ValidSet <- data1[-train,]
summary(TrainSet)
summary(ValidSet)
# Create a Random Forest model with default parameters
model1 <- randomForest(condition ~ ., data = TrainSet, mtry = 2, importance = TRUE)
model1
# Fine tuning parameters of Random Forest model
model2 <- randomForest(condition ~ ., data = TrainSet, ntree = 500, mtry = 6, importance = TRUE)
model2
# Predicting on train set
predTrain <- predict(model2, TrainSet, type = "class")
# Checking classification accuracy
table(predTrain, TrainSet$condition)
# Predicting on Validation set
predValid <- predict(model2, ValidSet, type = "class")
# Checking classification accuracy
mean(predValid == ValidSet$condition)
table(predValid,ValidSet$condition)
# To check important variables
importance(model2)
varImpPlot(model2)
# Using For loop to identify the right mtry for model
a=c()
i=5
for (i in 3:7) {
model3 <- randomForest(condition ~ ., data = TrainSet, ntree = 500, mtry = i, importance = TRUE)
predValid <- predict(model3, ValidSet, type = "class")
a[i-2] = mean(predValid == ValidSet$condition)
}
a

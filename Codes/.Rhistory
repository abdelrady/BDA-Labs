head(data)
#create prediction object that can be examined with the plotting function of ROCR
#first argument is predicted probabilities for class ActualClass, second one is true class labels
pred <- prediction(predictions = data$Probability, labels = data$ActualClass)
?performance
#compute tpr and fpr from prediction object
perf <- performance(pred, measure = "tpr", x.measure = "fpr")
plot(perf, main="ROC curve", col = "blue")
#compute area under the curve from prediction object
#perf.auc is a performance object
perf.auc <- performance(pred, measure = "auc")
#the auc is stored as a list in the y.values slot
#unlist() simplifies lists to a vector of numeric values
unlist(perf.auc@y.values)
x <- c(10, 20, 30, 40, 50)
y <- c(2, 4)
x*y
x*y
x <- c(10, 20, 30, 40)
y <- c(2, 4)
x*y
y <- c(2, 4, 6)
x*y
x*y
40:34
Letters[1:4]
LETTERS[1:4]
LETTERS[1:26]
LETTERS[1:27]
LETTERS[1:28]
x<-10
x
mode(x)
x
2^5
8%%3
15%%4
(5<=8)&(4>=9)
(5<=8)|(4>=9)
v <- 2:8
v
y<-5
print(y %in% v)
firstname <- 'Donald'
lastname <- 'Trump'
fullname <- paste(firstname, lastname)
fullname
fullname <- paste(firstname, lastname, sep = ", ")
fullname
names <- c('joe','andy','bob')
ages <- c(25, 45, 34)
namesAndages <- c(names, ages)
namesAndages
length(namesAndages)
#Any value written within a pair of single quote or double quotes in R is treated as a string
hs.year <- c("Senior", "Freshman","Junior", "Senior", "Sophmore", "Freshman")
mode(hs.year)
h <- factor(hs.year)
mode(hs.year)
summary(h)
summary(hs.year)
summary(h)
data <- c(90,95,92,78,46,51,77,98,90,85,78,61,100,89,87)
i <- 1
seq(1, by=2, length = 5)
seq(1, 10, by=2)
seq(1, 15, by=2)
m <- ordered(hs.year)
m
data <- c(90,95,92,78,46,51,77,98,90,85,78,61,100,89,87)
i <- 1
repeat{
if(data[i] > 80) {
print(data[i])
i <- i+1
}
else
break
}
grades <- matrix(data, nrow = 3, ncol = 5, byrow = TRUE)
grades
grades <- matrix(data, nrow = 3, ncol = 5, byrow = FALSE)
grades
grades[1,2]
grades <- matrix(data, nrow = 5, ncol = 3, byrow = TRUE)
grades
grades[1,2]
dimnames(grades) <- list(c("bob", "joe", "andy", "mary","alice"), c("English", "Math", "Science"))
grades
name <- c("Jennifer", "Alex", "Wes", "Ryan")
sex <- c("Female", "Male","Male","Male")
age.diagnosis <- c(49, 57,69,75)
year.diagnosis <- c(10, 5,2,12)
hosp.info <- data.frame(name,sex,age.diagnosis, year.diagnosis)
hosp.info
grades[1:5,2:3]
grades
grades[1:5,2:3]
grades[c(1,3,5),2:3]
hosp.info$new.age <- hosp.info$age.diagnosis + hosp.info$year.diagnosis
hosp.info
dim(grades)
grades
nrows(grades)
nrow(grades)
ncol(grades)
hosp.info
hosp.info[,1]
hosp.info[1:2,1]
hosp.info
hosp.info
ab < c(1,3,4,5,6,7,8)
summary(ab)
ab <- c(1,3,4,5,6,7,8)
summary(ab)
sum(ab)
sum(ab)/8
sum(ab)/length(ab)
summary(ab)
iqr(ab)
IQR(ab)
ab <- c(1,2,3,4,5,6,7,8)
sum(ab)/length(ab)
summary(ab)
IQR(ab)
ac <- c(35,49,59,61,62,64,65,66,66,68,68,68,69,70,70,72,77,77,84,86)
summary(ac)
sort(c( 45, 80, 83, 78, 75, 77, 79, 83, 83, 100))
ad <- sort(c( 45, 80, 83, 78, 75, 77, 79, 83, 83, 100))
Quantile(ad, 0.25)
Quartile(ad, 0.25)
quantile(ad, 0.25)
ad
IQR(ad)
mean(ad)
ad < mean(ad)
ae <- c( 45, 80, 83, 78, 75, 77, 79, 83, 83, 100)
ad <- sort(ae)
ad
ae < mean(ae)
setX <- c(45, 80, 83, 78, 75, 77, 79, 83, 83, 100)
# Prob 1
#1.a
set.mean <- mean(setX)
#1.b
set.median <- median(setX)
#1.c
set.variance <- var(setX)
#1.d
set.std <- sd(setX)
#1.e
set.iqr <- IQR(setX)
setX <- c(45, 80, 83, 78, 75, 77, 79, 83, 83, 100)
# Prob 1
#1.a
set.mean <- mean(setX)
#1.b
set.median <- median(setX)
#1.c
set.variance <- var(setX)
#1.d
set.std <- sd(setX)
#1.e
set.iqr <- IQR(setX)
# Prob 3
# 3.a
set.3a = setX < set.mean
# 3.b
setX[setX < set.mean]
# 3.c
setX[seq(1, length(setX), by = 2)]
# 3.d
scores.matrix <- matrix(setX, nrow=2, ncol=5, byrow = TRUE)
print(scores.matrix)
# 3.e
scores.matrix[,c(1,ncol(scores.matrix))]
# 3.f
dimnames(scores.matrix) <- list(
paste("Student_", seq(1:nrow(scores.matrix)), sep=""),
paste("Quiz_", seq(1:ncol(scores.matrix)), sep="")
)
print(scores.matrix)
# Prob 4
Name = c("Pomana", "Williams","Stanford","Princeton", "Yale")
State = c("CA", "MA", "CA","NJ", "CT")
Cost = c(62632, 64020, 62801, 58965, 63970)
Population = c(1610, 2150, 18346, 8014, 12109)
colleges.info = data.frame(Name, State, Cost, Population)
# 4.a
summary(colleges.info$State)
summary(colleges.info$Cost)
#4.b
subset(colleges.info, Population > 5000)
#4.b
colleges.info.2016 <- colleges.info[,c(1:2,4)]
colleges.info.2016$Cost <- round(colleges.info$Cost * 1.05, 0)
print(colleges.info.2016)
colleges.info = data.frame(Name, State, Cost, Population)
colleges.info
#Read in data
selfesteem.data <- read.csv(".\\lab02.csv")
selfesteem.data
attach(selfesteem.data)
#Basic Scatterplot
?plot
plot(Height,Selfesteem)
#Scatterplot with labs, and controlling axes
plot(Height,Selfesteem,
main="Scatterplot of Person Height versus Self Esteem",
xlab = "Height", ylab="Self Esteem",
xlim=c(min(Height), max(Height)), ylim=c(min(Selfesteem), max(Selfesteem)), pch = 8, col="seagreen3",
cex=1.5, cex.lab = 1.5, cex.main = 1.5)
x.mean <- mean(selfesteem.data$Height)
x.mean
y.mean <- mean(selfesteem.data$Selfesteem)
y.mean
points(65.28, 3.76, col="red", pch=19)
points(x.mean, y.mean, col="red", pch=19)
x.sd <- sd(Height)
x.sd
y.sd <- sd(Selfesteem)
y.sd
#Calculate Sample Correlation
cor(Height,Selfesteem, use="pairwise.complete.obs")
#Simple Linear Regression
m <- lm(Selfesteem~Height)
m
#Calculate Sample Correlation
cor(Height,Selfesteem, use="pairwise.complete.obs")
#Simple Linear Regression
m <- lm(Selfesteem~Height)
m
#Adding regression line to the current plot
abline(m,col="red")
#Request important summary information from R about the model
summary(m)
beta1 <- cor(selfesteem.data$Height,selfesteem.data$Selfesteem) * sd(selfesteem.data$Selfesteem)/sd(selfesteem.data$Height)
beta1
beta0 <- mean(selfesteem.data$Selfesteem)-beta1*mean(selfesteem.data$Height)
beta0
fitted(m)
?fitted
#compute R square by hand
totalss <-sum((selfesteem.data$Selfesteem -mean(selfesteem.data$Selfesteem))^2)
selfesteem.data$Selfesteem
regss <-sum((fitted(m) -mean(selfesteem.data$Selfesteem))^2)
#compute R square by hand
totalss <-sum((selfesteem.data$Selfesteem -mean(selfesteem.data$Selfesteem))^2)
regss <-sum((fitted(m) -mean(selfesteem.data$Selfesteem))^2)
regss <-sum((fitted(m) -mean(selfesteem.data$Selfesteem))^2)
#compute R square by hand
totalss <-sum((selfesteem.data$Selfesteem -mean(selfesteem.data$Selfesteem))^2)
residss <-sum((selfesteem.data$Selfesteem-fitted(m))^2)
rsquare <- regss/totalss
rsquare
#Read in data
selfesteem.data <- read.csv(".\\lab02.csv")
selfesteem.data
attach(selfesteem.data)
#Basic Scatterplot
?plot
plot(Height,Selfesteem)
#Scatterplot with labs, and controlling axes
plot(Height,Selfesteem,
main="Scatterplot of Person Height versus Self Esteem",
xlab = "Height", ylab="Self Esteem",
xlim=c(min(Height), max(Height)), ylim=c(min(Selfesteem), max(Selfesteem)), pch = 8, col="seagreen3",
cex=1.5, cex.lab = 1.5, cex.main = 1.5)
x.mean <- mean(selfesteem.data$Height)
x.mean
y.mean <- mean(selfesteem.data$Selfesteem)
y.mean
points(x.mean, y.mean, col="red", pch=19)
x.sd <- sd(Height)
x.sd
y.sd <- sd(Selfesteem)
y.sd
#Calculate Sample Correlation
cor(Height,Selfesteem, use="pairwise.complete.obs")
#Simple Linear Regression
m <- lm(Selfesteem~Height)
m
#Adding regression line to the current plot
abline(m,col="red")
#Request important summary information from R about the model
summary(m)
beta1 <- cor(selfesteem.data$Height,selfesteem.data$Selfesteem) * sd(selfesteem.data$Selfesteem)/sd(selfesteem.data$Height)
#Read in data
prestige.data <- read.csv(".\\lab3-data.csv")
prestige.data
#Basic Scatterplot
?plot
plot(prestige.data$PrestigeScore,prestige.data$EducationLevel)
#Scatterplot with labs, and controlling axes
plot(prestige.data$PrestigeScore,prestige.data$EducationLevel,
main="Scatterplot of Person Prestige Score Based On Education Level",
xlab = "EducationLevel", ylab="Prestige Score",
xlim=c(10, 90), ylim=c(5, 20), pch = 8, col="seagreen3",
cex=1.5, cex.lab = 1.5, cex.main = 1.5)
#Calculate Sample Correlation
cor(prestige.data$EducationLevel,prestige.data$PrestigeScore, use="pairwise.complete.obs")
#Simple Linear Regression
m <- lm(prestige.data$PrestigeScore~prestige.data$EducationLevel+prestige.data$Income+prestige.data$PercentOfWomen)
m
#Request important summary information from R about the model
summary(m)
#compute R^2
totalss <-sum((prestige.data$PrestigeScore - mean(prestige.data$PrestigeScore))^2)
regss <-sum((fitted(m) -mean(prestige.data$PrestigeScore))^2)
residss <-sum((prestige.data$PrestigeScore-fitted(m))^2)
rsquare <- regss/totalss
rsquare
#Read in data
prestige.data <- read.csv(".\\lab3-data.csv")
prestige.data
#Basic Scatterplot
?plot
plot(prestige.data$PrestigeScore,prestige.data$EducationLevel)
#Scatterplot with labs, and controlling axes
plot(prestige.data$PrestigeScore,prestige.data$EducationLevel,
main="Scatterplot of Person Prestige Score Based On Education Level",
xlab = "EducationLevel", ylab="Prestige Score",
xlim=c(10, 90), ylim=c(5, 20), pch = 8, col="seagreen3",
cex=1.5, cex.lab = 1.5, cex.main = 1.5)
#Calculate Sample Correlation
cor(prestige.data$EducationLevel,prestige.data$PrestigeScore, use="pairwise.complete.obs")
#read in data
data <- read.csv(".\\lab4-data.csv")
data
attach(data)
# summary for 2 columns (tratement, pain)
summary(data[,c(1,length(data))])
t <- table(Treatment, Pain)
t
data
addmargins(t)
prop.table(t, 1) # 1 means summarize by column, 2 means summarize by row
# convert strings into numeric for GLM
data$Treatment <- ifelse(data$Treatment == "New Treatment", 1, 0)
#simple logistic regression model
m<-glm(data$Pain ~ data$Treatment, family = binomial)
summary(m)
# convert strings into numeric for GLM
data$Treatment <- ifelse(data$Treatment == "New Treatment", 1, 0)
#simple logistic regression model
m<-glm(data$Pain ~ data$Treatment, family = binomial)
summary(m)
#compute McFadden's pseudo-R squared
#m<-glm(data$event ~ data$chol, family = binomial)
nullm <- glm(data$Pain ~ 1, family="binomial")
rsquare = 1-logLik(m)/logLik(nullm)
rsquare
#read in data
data <- read.csv(".\\lab4-data.csv")
data
attach(data)
# summary for 2 columns (tratement, pain)
summary(data[,c(1,length(data))])
t <- table(Treatment, Pain)
t
addmargins(t)
prop.table(t, 1) # 1 means summarize by column, 2 means summarize by row
# convert strings into numeric for GLM
data$Treatment <- ifelse(data$Treatment == "New Treatment", 1, 0)
#simple logistic regression model
m<-glm(data$Pain ~ data$Treatment, family = binomial)
summary(m)
#compute McFadden's pseudo-R squared
#m<-glm(data$event ~ data$chol, family = binomial)
nullm <- glm(data$Pain ~ 1, family="binomial")
rsquare = 1-logLik(m)/logLik(nullm)
rsquare
#multiple logistic regression model
multi.m<-glm(data$Pain ~ data$Treatment+data$Age+data$Severe, family = binomial)
summary(multi.m)
multi.m$coefficients[2]
multi.m$coefficients
# Odd per 1 unit increase in treatment
exp(multi.m$coefficients[2])
# Odd per 10 unit increase in age
exp(multi.m$coefficients[3]*10)
# Odd per 1 unit increase in severity
exp(multi.m$coefficients[4])
multi.rsquare = 1-logLik(multi.m)/logLik(nullm)
rsquare
multi.rsquare
install.packages("naivebayes")
library("naivebayes")
install.packages("naivebayes")
install.packages("naivebayes")
library("naivebayes")
#load the data set
data(iris)
head(iris)
summary(iris$Species)
iris
nb <- naive_bayes(iris$Species ~ ., data = iris)
summary(iris$Species)
nb <- naive_bayes(iris$Species ~ ., data = iris)
nb
#using the naive bayes' model for prediction on the training data
predict(nb, iris[,-5])
#classification result
table(predict(nb, iris[,-5]), iris[,5])
sum(predict(nb, iris[,-5])!=iris[,5])
iris[,-5]
install.packages("arules")
library("arules")
#create a sparse matrix
grocery <- read.transactions(".\\demoData\\grocery.csv",  sep = ",")
#create a sparse matrix
grocery <- read.transactions(".\\grocery.csv",  sep = ",")
summary(grocery)
#R has this dataset Groceries with 9835 rows
data("Groceries")
summary(Groceries)
#look at first five transactions
inspect(Groceries[1:5])
#look at first five transactions
inspect(Groceries[1:5])
#visualize the first 10 rows of sparse matrix
image(Groceries[1:10])
##visualize the randomly sampled 100 rows of sparse matrix
image(sample(Groceries,100))
#examine a particular item(a column of data)
#the proportion of transactions that contain the item
itemFrequency(Groceries[, 1:3])
#examine a particular item(a column of data)
#the proportion of transactions that contain the item
itemFrequency(Groceries[, 1:3])
#plot frequent items with min support = 0.1
itemFrequencyPlot(Groceries, support = 0.1)
#plot top 20 frequent items
itemFrequencyPlot(Groceries, topN = 20)
#use apriori to generate rules
rules <- apriori(Groceries,
parameter = list(support = 0.006, confidence = 0.25, minlen = 2))
summary(rules)
inspect(rules[1:5])
#get top five highest lift rules
inspect(sort(rules, by="lift")[1:5])
#plot frequent items with min support = 0.1
itemFrequencyPlot(Groceries, support = 0.1)
Groceries[, 1:3]
print(Groceries[, 1:3])
print(Groceries[1, 1:3])
summary(grocery)
#examine a particular item(a column of data)
#the proportion of transactions that contain the item
itemFrequency(Groceries[, 1:3])
#plot frequent items with min support = 0.1
itemFrequencyPlot(Groceries, support = 0.1)
#plot frequent items with min support = 0.1
itemFrequencyPlot(Groceries, support = 0.1)
#plot top 20 frequent items
itemFrequencyPlot(Groceries, topN = 20)
#use apriori to generate rules
rules <- apriori(Groceries,
parameter = list(support = 0.006, confidence = 0.25, minlen = 2))
summary(rules)
inspect(rules[1:5])
rules
summary(rules)
inspect(rules[1:5])
#plot top 20 frequent items
itemFrequencyPlot(Groceries, topN = 20)
#plot frequent items with min support = 0.1
itemFrequencyPlot(Groceries, support = 0.1)
#plot top 20 frequent items
itemFrequencyPlot(Groceries, topN = 10)
#plot frequent items with min support = 0.1
itemFrequencyPlot(Groceries, support = 0.2)
#plot frequent items with min support = 0.1
itemFrequencyPlot(Groceries, support = 0.15)
#get top five highest lift rules
inspect(sort(rules, by="lift")[1:5])
#examine a particular item(a column of data)
#the proportion of transactions that contain the item
itemFrequency(Groceries[, 1:3])
#find subset of the rules with berrries appearing in the rule
sub.rules <- subset(rules, items %in% "tropical fruit")
inspect(sub.rules)
inspect(sub.rules)
items
rules
?rules
#find subset of the rules with berrries appearing in the rule
sub.rules <- subset(rules, rhs %in% "tropical fruit")
#find subset of the rules with berrries appearing in the rule
sub.rules <- subset(rules, rhs %in% "tropical fruit")
inspect(sub.rules)
#find subset of the rules with berrries appearing in the rule
sub.rules <- subset(rules, rhs %in% "tropical fruit")
inspect(sub.rules)
sub.rules.2 <- subset(rules, items %in% "berries" || "yogurt" && lift > 3)
sub.rules.2 <- subset(rules, items %in% "berries" | "yogurt" & lift > 3)
sub.rules.2 <- subset(rules, (items %in% "berries" || items %in% "yogurt") && lift > 3)
inspect(sub.rules.2)
sub.rules.2 <- subset(rules, (items %in% "berries" || items %in% "yogurt") && lift > 1)
inspect(sub.rules.2)
#get top five highest lift rules
inspect(sort(rules, by="lift")[1:5])
sub.rules.2 <- subset(rules, (items %in% "berries" || items %in% "yogurt"))
inspect(sub.rules.2)
sub.rules.2 <- subset(rules, (items %in% "berries" | items %in% "yogurt"))
inspect(sub.rules.2)
sub.rules.2 <- subset(rules, (items %in% "berries" | items %in% "yogurt") & lift > 1)
inspect(sub.rules.2)
sub.rules.2 <- subset(rules, (items %in% "berries" | items %in% "yogurt") & lift > 3)
inspect(sub.rules.2)
sub.rules.2 <- subset(rules, (items %in% "berries" | items %in% "yogurt") & lift > 3)
inspect(sub.rules.2)
